---
layout: post
title:  "About Me"
date:   2019-03-23 21:03:36 +0530
categories: intro
---


## About Me
I am an Assistant Professor in the [School of Electrical Engineering] at KAIST (Korea Advanced Institute of Science and Technology). I was an Applied Scientist at Adobe [Firefly], and a Postdoctoral Fellow at the [Yale Institute for Foundations of Data Science] (FDS). I obtained my Ph.D. degree in the School of Electrical Engineering at KAIST, where I was advised by [Jinwoo Shin]. I received an M.S. in Electrical engineering and a B.S. in Electrical Engineering and Mathematics (minored) from KAIST.  My research interests focus on approximate algorithm design and analysis for large-scale machine learning and its applications. In 2019, I was fortunate to be a recipient of [Microsoft Research Asia Fellowship 2019]. In 2024, with Amin Karbasi and Amir Zandieh, we were selected as recipients of 2024 [Roberts Innovation Fund Award] for research on making AI more powerful and cost-effective.

<!-- Here is my [CV] (Last update: Jun 2023). -->

<br/>
## Contact
Email : insu.han@kaist.ac.kr <br/>
Office: N1 914, 291 Daehak-ro, Daejeon, South Korea 

[School of Electrical Engineering]: https://ee.kaist.ac.kr/
[Firefly]: https://firefly.adobe.com/
[Yale Institute for Foundations of Data Science]: https://fds.yale.edu/
[Amin Karbasi]: http://iid.yale.edu/
[Jinwoo Shin]: http://alinlab.kaist.ac.kr/shin.html
[CV]: https://www.dropbox.com/s/p7co802hdvgkguh/cv_2023.pdf?dl=0
[Roberts Innovation Fund Award]: https://ventures.yale.edu/2023-2024-roberts-awards 
<!-- 
<br/>
## Awards
-----
I am a recipient of [Microsoft Research Asia Fellowship 2019]. <br/>
-->

[Microsoft Research Asia Fellowship 2019]: https://www.microsoft.com/en-us/research/academic-program/fellowships-microsoft-research-asia/ 


<br/>
## Publications
-----

**BalanceKV: KV Cache Compression through Discrepancy Theory** <br/>
[[paper][balancekv_paper]{:target="_blank"}]<br/>
(α-β) <U>Insu Han</U>, Michael Kapralov, Ekaterina Kochetkova, Kshiteej Sheth, Amir Zandieh <br/>
Under Review
<br/>

**PolarQuant: Quantizing KV Caches with Polar Transformation** <br/>
[[paper][polarquant_paper]{:target="_blank"}]<br/>
(α-β) <U>Insu Han</U>, Praneeth Kacham, Amin Karbasi, Vahab Mirrokni, Amir Zandieh <br/>
Under Review
<br/>


**QJL: 1-Bit Quantized JL Transform for KV Cache Quantization with Zero Overhead** <br/>
[[paper][gjl_paper]{:target="_blank"}][[code][qjl_code]{:target="_blank"}] <br/>
Amir Zandieh, Majid Daliri, <U>Insu Han</U> <br/>
The Annual AAAI Conference on Artificial Intelligence (AAAI) 2025
<br/>
	
**Cell2Sentence: Teaching Large Language Models the Language of Biology** <br/>
[[paper][cell2sen_paper]{:target="_blank"}]<br/>
Daniel Levine, Syed A Rizvi, Sacha Lévy, Nazreen Pallikkavaliyaveetil, David Zhang, Xingyu Chen, Sina Ghadermarzi, Ruiming Wu, Zihe Zheng, Ivan Vrkic, Anna Zhong, Daphne Raskin, <U>Insu Han</U>, Antonio Henrique de Oliveira Fonseca, Josue Ortega Caro, Amin Karbasi, Rahul Madhav Dhodapkar, David van Dijk<br/>
International Conference on Machine Learning (ICML) 2024
<br/>

**SubGen: Token Generation in Sublinear Time and Memory** <br/>
[[paper][subgen_paper]{:target="_blank"}]<br/>
Amir Zandieh\*, <ins>Insu Han</ins>\*, Vahab Mirrokni, Amin Karbasi (\*Equal contribution)<br/> 
Under Review
<br/>

**HyperAttention: Long-context Attention in Near-Linear Time** <br/>
[[paper][hyperattn_paper]{:target="_blank"}]<br/>
(α-β) <U>Insu Han</U>, Rajesh Jayaram, Amin Karbasi, Vahab Mirrokni, David P. Woodruff, Amir Zandieh<br/>
International Conference on Learning Representations (ICLR) 2024
<br/>

**Near Optimal Reconstruction of Spherical Harmonic Expansions** <br/>
[[paper][gegen_recon_paper]{:target="_blank"}]<br/>
Amir Zandieh, <U>Insu Han</U>, Haim Avron<br/>
Advances in Neural Information Processing Systems (NeurIPS) 2023
<br/>

**KDEformer: Accelerating Transformers via Kernel Density Estimation** <br/>
[[paper][kdeformer_paper]{:target="_blank"}] <br/>
Amir Zandieh, <ins>Insu Han</ins>\*, Majid Daliri\*, Amin Karbasi (\*Equal contribution)<br/>
International Conference on Machine Learning (ICML) 2023
<br/>


**Fast Neural Kernel Embeddings for General Activations** <br/>
[[paper][fast_neural_kernel_paper]{:target="_blank"}][[code][fast_neural_kernel_code]{:target="_blank"}, also implemented in [Neural Tangents]{:target="_blank"} library]<br/>
<U>Insu Han</U>, Amir Zandieh, Jaehoon Lee, Roman Novak, Lechao Xiao, Amin Karbasi<br/>
Advances in Neural Information Processing Systems (NeurIPS) 2022
<br/>

**Scalable MCMC Sampling for Nonsymmetric Determinantal Point Processes** <br/>
[[paper][kndpp_mcmc_sampling_paper]{:target="_blank"}][[code][kndpp_mcmc_sampling_code]{:target="_blank"}] <br/>
<U>Insu Han</U>, Mike Gartrell, Elvis Dohmatob, Amin Karbasi<br/>
International Conference on Machine Learning (ICML) 2022, Long Presentation (118/5630=2%)
<br/>

**Random Gegenbauer Features for Scalable Kernel Methods** <br/>
[[paper][gegen_rf_paper]{:target="_blank"}]<br/>
<U>Insu Han</U>\*, Amir Zandieh\*, Haim Avron (\*Equal contribution)<br/>
International Conference on Machine Learning (ICML) 2022, Long Presentation (118/5630=2%)
<br/>

**Scalable Sampling for Nonsymmetric Determinantal Point Processes** <br/>
[[paper][ndpp_sampling_paper]{:target="_blank"}][[code][ndpp_sampling_code]{:target="_blank"}]<br/>
<U>Insu Han</U>, Mike Gartrell, Jennifer Gillenwater, Elvis Dohmatob, Amin Karbasi<br/>
International Conference on Learning Representations (ICLR) 2022, Spotlight Presentation
<br/>


**Scaling Neural Tangent Kernels via Sketching and Random Features** <br/>
[[paper][ntk_paper]{:target="_blank"}][[code][ntk_rf_code]{:target="_blank"}]<br/>
Amir Zandieh\*, <U>Insu Han</U>\*, Haim Avron, Neta Shoham, Chaewon Kim, Jinwoo Shin (\*Equal contribution)<br/>
Advances in Neural Information Processing Systems (NeurIPS) 2021
<br/>

**Scalable Learning and MAP Inference for Nonsymmetric Determinantal Point Processes** <br/>
[[paper][ndpp_paper]][[code][ndpp_code]]<br/>
Mike Gartrell, <U>Insu Han</U>, Elvis Dohmatob, Jennifer Gillenwater and Victor-Emmanuel Brunel <br/>
International Conference on Learning Representations (ICLR) 2021, Oral Presentation (58/2997=1.8%)
<br/>

**Polynomial Tensor Sketch for Element-wise Function of Low-Rank Matrix** <br/>
[[paper][poly_paper]][[code][poly_code]]<br/>
<U>Insu Han</U>, Haim Avron and Jinwoo Shin <br/>
International Conference on Machine Learning (ICML) 2020
<br/>

**MAP Inference for Customized Determinantal Point Processes via Maximum Inner Product Search** <br/>
[[paper][fastdppmap_aistats20]][[code][dppmips_code]]<br/>
<U>Insu Han</U> and Jennifer Gillenwater <br/>
International Conference on Artificial Intelligence and Statistics (AISTATS) 2020
<br/>

**Stochastic Chebyshev Gradient Descent for Spectral Optimization** <br/>
[[paper][specopt_paper]][[poster][specopt_poster]][[video][specopt_video]]<br/>
<U>Insu Han</U>, Haim Avron and Jinwoo Shin <br/>
Neural Information Processing Systems (NeurIPS) 2018, Spotlight Presentation (168/4856=3.5%)

**Faster Greedy MAP Inference for Determinantal Point Processes** <br/>
[[paper][fastdpp_paper]][[code][fastdpp_code]][[video][fastdpp_video]]<br/>
<U>Insu Han</U>, Prabhanjan Kambadur, Kyoungsoo Park and Jinwoo Shin <br/>
International Conference on Machine Learning (ICML) 2017

**Approximating Spectral Sums of Large-scale Matrices using Stochastic Chebyshev Approximations** <br/>
[[paper][specsum_paper]]<br/>
<U>Insu Han</U>, Dmitry Malioutov, Haim Avron and Jinwoo Shin <br/>
SIAM Journal on Scientific Computing (SISC) 2017

**Large-scale Log-determinant Computation through Stochastic Chebyshev Expansions** <br/>
[[paper][logdet_paper]][[code][logdet_code]][[video][logdet_video]]<br/>
<U>Insu Han</U>, Dmitry Malioutov, and Jinwoo Shin <br/>
International Conference on Machine Learning (ICML) 2015

[subgen_paper]:https://arxiv.org/pdf/2402.06082.pdf
[Neural Tangents]: https://github.com/google/neural-tangents
[kndpp_mcmc_sampling_paper]:https://arxiv.org/pdf/2207.00486.pdf
[kndpp_mcmc_sampling_code]:https://github.com/insuhan/ndpp-mcmc-sampling
[fast_neural_kernel_paper]:https://arxiv.org/pdf/2209.04121.pdf
[fast_neural_kernel_code]:https://github.com/insuhan/ntk_activations
[gegen_recon_paper]: https://arxiv.org/pdf/2202.12995.pdf
[gegen_rf_paper]: https://arxiv.org/pdf/2202.03474.pdf
[ndpp_sampling_paper]: https://openreview.net/forum?id=BB4e8Atc1eR
[ndpp_sampling_code]: https://github.com/insuhan/nonsymmetric-dpp-sampling
[ntk_rf_code]: https://github.com/insuhan/ntk-sketch-rf
[dppmips_code]: https://github.com/insuhan/dppmapmips
[ndpp_code]: https://github.com/cgartrel/nonsymmetric-DPP-learning/tree/scalable
[ndpp_paper]: https://openreview.net/forum?id=HajQFbx_yB
[poly_code]: https://github.com/insuhan/polytensorsketch
[poly_paper]: http://proceedings.mlr.press/v119/han20a/han20a.pdf
[specopt_paper]: https://papers.nips.cc/paper/7968-stochastic-chebyshev-gradient-descent-for-spectral-optimization.pdf
[specopt_poster]: http://alinlab.kaist.ac.kr/resource/poster_nips18_specopt.pdf
[specopt_video]: https://www.youtube.com/watch?v=0Sx9G3-fOwU&feature=youtu.be
[fastdpp_paper]: http://proceedings.mlr.press/v70/han17a/han17a.pdf
[fastdpp_code]: https://github.com/insuhan/fastdppmap
[fastdpp_video]: https://vimeo.com/240776466
[specsum_paper]: https://epubs.siam.org/doi/pdf/10.1137/16M1078148
[logdet_paper]: http://proceedings.mlr.press/v37/hana15.pdf
[logdet_code]: http://alinlab.kaist.ac.kr/resource/logdet_code.zip
[logdet_video]: http://videolectures.net/icml2015_han_log_determinant_computation/
[fastdppmap_aistats20]: http://alinlab.kaist.ac.kr/resource/fastdppmap_aistats2020.pdf
[ntk_paper]: https://arxiv.org/pdf/2106.07880.pdf
[kdeformer_paper]: https://arxiv.org/pdf/2302.02451.pdf
[hyperattn_paper]: https://arxiv.org/pdf/2310.05869.pdf
[cell2sen_paper]: https://openreview.net/pdf?id=EWt5wsEdvc
[gjl_paper]: https://arxiv.org/pdf/2406.03482
[polarquant_paper]: https://arxiv.org/pdf/2502.02617
[qjl_code]: https://github.com/amirzandieh/QJL
[balancekv_paper]: https://arxiv.org/pdf/2502.07861

<br/>
## Research experiences
-----

- **[Summer 2019]** Research intern at Google New York City with [Jennifer Gillenwater] <br/>
- **[Spring 2018]** Visting student at Tel Aviv University with [Haim Avron] <br/>

[Jennifer Gillenwater]: http://jgillenw.com/
[Haim Avron]: http://www.math.tau.ac.il/~haimav/
