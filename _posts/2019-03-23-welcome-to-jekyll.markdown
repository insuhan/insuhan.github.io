---
layout: post
title:  "About Me"
date:   2019-03-23 21:03:36 +0530
categories: intro
---


## About Me
I am an [FDS] Postdoctoral Fellow at Yale University. Previously, I obtained my Ph.D. degree in the School of Electrical Engineering at Korea Advanced Institute of Science and Technology (KAIST), where I am advised by [Jinwoo Shin]. I recieved an M.S. in Electrical engineering and a B.S. in Electrical Engineering and Mathematics (minored) from KAIST.  My research interests focus on approximate algorithm design and analysis for large-scale machine learning and its applications. In 2019, I was fortunate to be a recipient of [Microsoft Research Asia Fellowship 2019].

Here is my [CV] (Last update: Jun 2023).

<br/>
## Contact
Email : insu.han at yale.edu <br/>

[FDS]: https://fds.yale.edu/
[Amin Karbasi]: http://iid.yale.edu/
[Jinwoo Shin]: http://alinlab.kaist.ac.kr/shin.html
[CV]: https://www.dropbox.com/s/p7co802hdvgkguh/cv_2023.pdf?dl=0

<!-- 
<br/>
## Awards
-----
I am a recipient of [Microsoft Research Asia Fellowship 2019]. <br/>
-->

[Microsoft Research Asia Fellowship 2019]: https://www.microsoft.com/en-us/research/academic-program/fellowships-microsoft-research-asia/ 


<br/>
## Publications
-----

**KDEformer: Accelerating Transformers via Kernel Density Estimation** <br/>
[[paper][kdeformer_paper]{:target="_blank"}] <br/>
Amir Zandieh, <U>Insu Han</U>, Majid Daliri, Amin Karbasi<br/>
International Conference on Machine Learning (ICML) 2023
<br/>


**Fast Neural Kernel Embeddings for General Activations** <br/>
[[paper][fast_neural_kernel_paper]{:target="_blank"}][[code][fast_neural_kernel_code]{:target="_blank"}, also implemented in [Neural Tangents]{:target="_blank"} library]<br/>
<U>Insu Han</U>, Amir Zandieh, Jaehoon Lee, Roman Novak, Lechao Xiao, Amin Karbasi<br/>
Advances in Neural Information Processing Systems (NeurIPS) 2022
<br/>

**Near Optimal Reconstruction of Spherical Harmonic Expansions** <br/>
[[paper][gegen_recon_paper]{:target="_blank"}]<br/>
Amir Zandieh, <U>Insu Han</U>, Haim Avron<br/>
Under review
<br/>

**Scalable MCMC Sampling for Nonsymmetric Determinantal Point Processes** <br/>
[[paper][kndpp_mcmc_sampling_paper]{:target="_blank"}][[code][kndpp_mcmc_sampling_code]{:target="_blank"}] <br/>
<U>Insu Han</U>, Mike Gartrell, Elvis Dohmatob, Amin Karbasi<br/>
International Conference on Machine Learning (ICML) 2022, Long Presentation (118/5630=2%)
<br/>

**Random Gegenbauer Features for Scalable Kernel Methods** <br/>
[[paper][gegen_rf_paper]{:target="_blank"}]<br/>
<U>Insu Han</U>, Amir Zandieh, Haim Avron<br/>
International Conference on Machine Learning (ICML) 2022, Long Presentation (118/5630=2%)
<br/>

**Scalable Sampling for Nonsymmetric Determinantal Point Processes** <br/>
[[paper][ndpp_sampling_paper]{:target="_blank"}][[code][ndpp_sampling_code]{:target="_blank"}]<br/>
<U>Insu Han</U>, Mike Gartrell, Jennifer Gillenwater, Elvis Dohmatob, Amin Karbasi<br/>
International Conference on Learning Representations (ICLR) 2022, Spotlight Presentation
<br/>


**Scaling Neural Tangent Kernels via Sketching and Random Features** <br/>
[[paper][ntk_paper]{:target="_blank"}][[code][ntk_rf_code]{:target="_blank"}]<br/>
<U>Insu Han</U>, Amir Zandieh, Haim Avron, Neta Shoham, Chaewon Kim, Jinwoo Shin<br/>
Advances in Neural Information Processing Systems (NeurIPS) 2021
<br/>

**Scalable Learning and MAP Inference for Nonsymmetric Determinantal Point Processes** <br/>
[[paper][ndpp_paper]][[code][ndpp_code]]<br/>
Mike Gartrell, <U>Insu Han</U>, Elvis Dohmatob, Jennifer Gillenwater and Victor-Emmanuel Brunel <br/>
International Conference on Learning Representations (ICLR) 2021, Oral Presentation (58/2997=1.8%)
<br/>

**Polynomial Tensor Sketch for Element-wise Function of Low-Rank Matrix** <br/>
[[paper][poly_paper]][[code][poly_code]]<br/>
<U>Insu Han</U>, Haim Avron and Jinwoo Shin <br/>
International Conference on Machine Learning (ICML) 2020
<br/>

**MAP Inference for Customized Determinantal Point Processes via Maximum Inner Product Search** <br/>
[[paper][fastdppmap_aistats20]][[code][dppmips_code]]<br/>
<U>Insu Han</U> and Jennifer Gillenwater <br/>
International Conference on Artificial Intelligence and Statistics (AISTATS) 2020
<br/>

**Stochastic Chebyshev Gradient Descent for Spectral Optimization** <br/>
[[paper][specopt_paper]][[poster][specopt_poster]][[video][specopt_video]]<br/>
<U>Insu Han</U>, Haim Avron and Jinwoo Shin <br/>
Neural Information Processing Systems (NeurIPS) 2018, Spotlight Presentation (168/4856=3.5%)

**Faster Greedy MAP Inference for Determinantal Point Processes** <br/>
[[paper][fastdpp_paper]][[code][fastdpp_code]][[video][fastdpp_video]]<br/>
<U>Insu Han</U>, Prabhanjan Kambadur, Kyoungsoo Park and Jinwoo Shin <br/>
International Conference on Machine Learning (ICML) 2017

**Approximating Spectral Sums of Large-scale Matrices using Stochastic Chebyshev Approximations** <br/>
[[paper][specsum_paper]]<br/>
<U>Insu Han</U>, Dmitry Malioutov, Haim Avron and Jinwoo Shin <br/>
SIAM Journal on Scientific Computing (SISC) 2017

**Large-scale Log-determinant Computation through Stochastic Chebyshev Expansions** <br/>
[[paper][logdet_paper]][[code][logdet_code]][[video][logdet_video]]<br/>
<U>Insu Han</U>, Dmitry Malioutov, and Jinwoo Shin <br/>
International Conference on Machine Learning (ICML) 2015

[Neural Tangents]: https://github.com/google/neural-tangents
[kndpp_mcmc_sampling_paper]:https://arxiv.org/pdf/2207.00486.pdf
[kndpp_mcmc_sampling_code]:https://github.com/insuhan/ndpp-mcmc-sampling
[fast_neural_kernel_paper]:https://arxiv.org/pdf/2209.04121.pdf
[fast_neural_kernel_code]:https://github.com/insuhan/ntk_activations
[gegen_recon_paper]: https://arxiv.org/pdf/2202.12995.pdf
[gegen_rf_paper]: https://arxiv.org/pdf/2202.03474.pdf
[ndpp_sampling_paper]: https://openreview.net/forum?id=BB4e8Atc1eR
[ndpp_sampling_code]: https://github.com/insuhan/nonsymmetric-dpp-sampling
[ntk_rf_code]: https://github.com/insuhan/ntk-sketch-rf
[dppmips_code]: https://github.com/insuhan/dppmapmips
[ndpp_code]: https://github.com/cgartrel/nonsymmetric-DPP-learning/tree/scalable
[ndpp_paper]: https://openreview.net/forum?id=HajQFbx_yB
[poly_code]: https://github.com/insuhan/polytensorsketch
[poly_paper]: http://proceedings.mlr.press/v119/han20a/han20a.pdf
[specopt_paper]: https://papers.nips.cc/paper/7968-stochastic-chebyshev-gradient-descent-for-spectral-optimization.pdf
[specopt_poster]: http://alinlab.kaist.ac.kr/resource/poster_nips18_specopt.pdf
[specopt_video]: https://www.youtube.com/watch?v=0Sx9G3-fOwU&feature=youtu.be
[fastdpp_paper]: http://proceedings.mlr.press/v70/han17a/han17a.pdf
[fastdpp_code]: https://github.com/insuhan/fastdppmap
[fastdpp_video]: https://vimeo.com/240776466
[specsum_paper]: https://epubs.siam.org/doi/pdf/10.1137/16M1078148
[logdet_paper]: http://proceedings.mlr.press/v37/hana15.pdf
[logdet_code]: http://alinlab.kaist.ac.kr/resource/logdet_code.zip
[logdet_video]: http://videolectures.net/icml2015_han_log_determinant_computation/
[fastdppmap_aistats20]: http://alinlab.kaist.ac.kr/resource/fastdppmap_aistats2020.pdf
[ntk_paper]: https://arxiv.org/pdf/2106.07880.pdf
[kdeformer_paper]: https://arxiv.org/pdf/2302.02451.pdf


<br/>
## Research experiences
-----

- **[Summer 2019]** Research intern at Google New York City with [Jennifer Gillenwater] <br/>
- **[Spring 2018]** Visting student at Tel Aviv University with [Haim Avron] <br/>

[Jennifer Gillenwater]: http://jgillenw.com/
[Haim Avron]: http://www.math.tau.ac.il/~haimav/
