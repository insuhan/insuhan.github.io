<!DOCTYPE html>
<html lang="en">
<head><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<link href="https://fonts.googleapis.com/css?family=Merriweather:300|Raleway:400,700" rel="stylesheet">
<link rel="stylesheet" href="/assets/css/style.css">
<title>About Me</title>
<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>About Me | Insu Han, Research Page</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="About Me" />
<meta name="author" content="Insu Han" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="I am a postdoc in the Department of Electrical Engineering at Yale University, working with Prof. Amin Karbasi. Previously, I obtained my Ph.D. degree in the School of Electrical Engineering at Korea Advanced Institute of Science and Technology (KAIST), where I am advised by Jinwoo Shin. I recieved an M.S. in Electrical engineering and a B.S. in Electrical Engineering and Mathematics (minored) from KAIST. My research interests focus on approximate algorithm design and analysis for large-scale machine learning and its applications. Here is my CV. Contact Email : insu.han at yale.edu Research experiences [Summer 2019] Research intern at Google New York City with Jennifer Gillenwater [Spring 2018] Visting student at Tel Aviv University with Haim Avron Awards I am a recipient of Microsoft Research Asia Fellowship 2019. Publications Fast Neural Kernel Embeddings for General Activations [paper][code] Insu Han, Amin Zandieh, Jaehoon Lee, Roman Novak, Lechao Xiao, Amin Karbasi To be appeared in Advances in Neural Information Processing Systems (NeurIPS) 2022 Near Optimal Reconstruction of Spherical Harmonic Expansions [paper] Amir Zandieh, Insu Han, Haim Avron Under review Scalable MCMC Sampling for Nonsymmetric Determinantal Point Processes [paper][code] Insu Han, Mike Gartrell, Elvis Dohmatob, Amin Karbasi International Conference on Machine Learning (ICML) 2022, Long Presentation (118/5630=2%) Random Gegenbauer Features for Scalable Kernel Methods [paper] Insu Han, Amir Zandieh, Haim Avron International Conference on Machine Learning (ICML) 2022, Long Presentation (118/5630=2%) Scalable Sampling for Nonsymmetric Determinantal Point Processes [paper][code] Insu Han, Mike Gartrell, Jennifer Gillenwater, Elvis Dohmatob, Amin Karbasi International Conference on Learning Representations (ICLR) 2022, Spotlight Presentation Scaling Neural Tangent Kernels via Sketching and Random Features [paper][code] Insu Han, Amir Zandieh, Haim Avron, Neta Shoham, Chaewon Kim, Jinwoo Shin Advances in Neural Information Processing Systems (NeurIPS) 2021 Scalable Learning and MAP Inference for Nonsymmetric Determinantal Point Processes [paper][code] Mike Gartrell, Insu Han, Elvis Dohmatob, Jennifer Gillenwater and Victor-Emmanuel Brunel International Conference on Learning Representations (ICLR) 2021, Oral Presentation (58/2997=1.8%) Polynomial Tensor Sketch for Element-wise Function of Low-Rank Matrix [paper][code] Insu Han, Haim Avron and Jinwoo Shin International Conference on Machine Learning (ICML) 2020 MAP Inference for Customized Determinantal Point Processes via Maximum Inner Product Search [paper][code] Insu Han and Jennifer Gillenwater International Conference on Artificial Intelligence and Statistics (AISTATS) 2020 Stochastic Chebyshev Gradient Descent for Spectral Optimization [paper][poster][video] Insu Han, Haim Avron and Jinwoo Shin Neural Information Processing Systems (NeurIPS) 2018, Spotlight Presentation (168/4856=3.5%) Faster Greedy MAP Inference for Determinantal Point Processes [paper][code][video] Insu Han, Prabhanjan Kambadur, Kyoungsoo Park and Jinwoo Shin International Conference on Machine Learning (ICML) 2017 Approximating Spectral Sums of Large-scale Matrices using Stochastic Chebyshev Approximations [paper] Insu Han, Dmitry Malioutov, Haim Avron and Jinwoo Shin SIAM Journal on Scientific Computing (SISC) 2017 Large-scale Log-determinant Computation through Stochastic Chebyshev Expansions [paper][code][video] Insu Han, Dmitry Malioutov, and Jinwoo Shin International Conference on Machine Learning (ICML) 2015" />
<meta property="og:description" content="I am a postdoc in the Department of Electrical Engineering at Yale University, working with Prof. Amin Karbasi. Previously, I obtained my Ph.D. degree in the School of Electrical Engineering at Korea Advanced Institute of Science and Technology (KAIST), where I am advised by Jinwoo Shin. I recieved an M.S. in Electrical engineering and a B.S. in Electrical Engineering and Mathematics (minored) from KAIST. My research interests focus on approximate algorithm design and analysis for large-scale machine learning and its applications. Here is my CV. Contact Email : insu.han at yale.edu Research experiences [Summer 2019] Research intern at Google New York City with Jennifer Gillenwater [Spring 2018] Visting student at Tel Aviv University with Haim Avron Awards I am a recipient of Microsoft Research Asia Fellowship 2019. Publications Fast Neural Kernel Embeddings for General Activations [paper][code] Insu Han, Amin Zandieh, Jaehoon Lee, Roman Novak, Lechao Xiao, Amin Karbasi To be appeared in Advances in Neural Information Processing Systems (NeurIPS) 2022 Near Optimal Reconstruction of Spherical Harmonic Expansions [paper] Amir Zandieh, Insu Han, Haim Avron Under review Scalable MCMC Sampling for Nonsymmetric Determinantal Point Processes [paper][code] Insu Han, Mike Gartrell, Elvis Dohmatob, Amin Karbasi International Conference on Machine Learning (ICML) 2022, Long Presentation (118/5630=2%) Random Gegenbauer Features for Scalable Kernel Methods [paper] Insu Han, Amir Zandieh, Haim Avron International Conference on Machine Learning (ICML) 2022, Long Presentation (118/5630=2%) Scalable Sampling for Nonsymmetric Determinantal Point Processes [paper][code] Insu Han, Mike Gartrell, Jennifer Gillenwater, Elvis Dohmatob, Amin Karbasi International Conference on Learning Representations (ICLR) 2022, Spotlight Presentation Scaling Neural Tangent Kernels via Sketching and Random Features [paper][code] Insu Han, Amir Zandieh, Haim Avron, Neta Shoham, Chaewon Kim, Jinwoo Shin Advances in Neural Information Processing Systems (NeurIPS) 2021 Scalable Learning and MAP Inference for Nonsymmetric Determinantal Point Processes [paper][code] Mike Gartrell, Insu Han, Elvis Dohmatob, Jennifer Gillenwater and Victor-Emmanuel Brunel International Conference on Learning Representations (ICLR) 2021, Oral Presentation (58/2997=1.8%) Polynomial Tensor Sketch for Element-wise Function of Low-Rank Matrix [paper][code] Insu Han, Haim Avron and Jinwoo Shin International Conference on Machine Learning (ICML) 2020 MAP Inference for Customized Determinantal Point Processes via Maximum Inner Product Search [paper][code] Insu Han and Jennifer Gillenwater International Conference on Artificial Intelligence and Statistics (AISTATS) 2020 Stochastic Chebyshev Gradient Descent for Spectral Optimization [paper][poster][video] Insu Han, Haim Avron and Jinwoo Shin Neural Information Processing Systems (NeurIPS) 2018, Spotlight Presentation (168/4856=3.5%) Faster Greedy MAP Inference for Determinantal Point Processes [paper][code][video] Insu Han, Prabhanjan Kambadur, Kyoungsoo Park and Jinwoo Shin International Conference on Machine Learning (ICML) 2017 Approximating Spectral Sums of Large-scale Matrices using Stochastic Chebyshev Approximations [paper] Insu Han, Dmitry Malioutov, Haim Avron and Jinwoo Shin SIAM Journal on Scientific Computing (SISC) 2017 Large-scale Log-determinant Computation through Stochastic Chebyshev Expansions [paper][code][video] Insu Han, Dmitry Malioutov, and Jinwoo Shin International Conference on Machine Learning (ICML) 2015" />
<link rel="canonical" href="http://143.248.53.212:4000/intro/2021/02/26/about-me.html" />
<meta property="og:url" content="http://143.248.53.212:4000/intro/2021/02/26/about-me.html" />
<meta property="og:site_name" content="Insu Han, Research Page" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-02-26T23:23:36+09:00" />
<script type="application/ld+json">
{"description":"I am a postdoc in the Department of Electrical Engineering at Yale University, working with Prof. Amin Karbasi. Previously, I obtained my Ph.D. degree in the School of Electrical Engineering at Korea Advanced Institute of Science and Technology (KAIST), where I am advised by Jinwoo Shin. I recieved an M.S. in Electrical engineering and a B.S. in Electrical Engineering and Mathematics (minored) from KAIST. My research interests focus on approximate algorithm design and analysis for large-scale machine learning and its applications. Here is my CV. Contact Email : insu.han at yale.edu Research experiences [Summer 2019] Research intern at Google New York City with Jennifer Gillenwater [Spring 2018] Visting student at Tel Aviv University with Haim Avron Awards I am a recipient of Microsoft Research Asia Fellowship 2019. Publications Fast Neural Kernel Embeddings for General Activations [paper][code] Insu Han, Amin Zandieh, Jaehoon Lee, Roman Novak, Lechao Xiao, Amin Karbasi To be appeared in Advances in Neural Information Processing Systems (NeurIPS) 2022 Near Optimal Reconstruction of Spherical Harmonic Expansions [paper] Amir Zandieh, Insu Han, Haim Avron Under review Scalable MCMC Sampling for Nonsymmetric Determinantal Point Processes [paper][code] Insu Han, Mike Gartrell, Elvis Dohmatob, Amin Karbasi International Conference on Machine Learning (ICML) 2022, Long Presentation (118/5630=2%) Random Gegenbauer Features for Scalable Kernel Methods [paper] Insu Han, Amir Zandieh, Haim Avron International Conference on Machine Learning (ICML) 2022, Long Presentation (118/5630=2%) Scalable Sampling for Nonsymmetric Determinantal Point Processes [paper][code] Insu Han, Mike Gartrell, Jennifer Gillenwater, Elvis Dohmatob, Amin Karbasi International Conference on Learning Representations (ICLR) 2022, Spotlight Presentation Scaling Neural Tangent Kernels via Sketching and Random Features [paper][code] Insu Han, Amir Zandieh, Haim Avron, Neta Shoham, Chaewon Kim, Jinwoo Shin Advances in Neural Information Processing Systems (NeurIPS) 2021 Scalable Learning and MAP Inference for Nonsymmetric Determinantal Point Processes [paper][code] Mike Gartrell, Insu Han, Elvis Dohmatob, Jennifer Gillenwater and Victor-Emmanuel Brunel International Conference on Learning Representations (ICLR) 2021, Oral Presentation (58/2997=1.8%) Polynomial Tensor Sketch for Element-wise Function of Low-Rank Matrix [paper][code] Insu Han, Haim Avron and Jinwoo Shin International Conference on Machine Learning (ICML) 2020 MAP Inference for Customized Determinantal Point Processes via Maximum Inner Product Search [paper][code] Insu Han and Jennifer Gillenwater International Conference on Artificial Intelligence and Statistics (AISTATS) 2020 Stochastic Chebyshev Gradient Descent for Spectral Optimization [paper][poster][video] Insu Han, Haim Avron and Jinwoo Shin Neural Information Processing Systems (NeurIPS) 2018, Spotlight Presentation (168/4856=3.5%) Faster Greedy MAP Inference for Determinantal Point Processes [paper][code][video] Insu Han, Prabhanjan Kambadur, Kyoungsoo Park and Jinwoo Shin International Conference on Machine Learning (ICML) 2017 Approximating Spectral Sums of Large-scale Matrices using Stochastic Chebyshev Approximations [paper] Insu Han, Dmitry Malioutov, Haim Avron and Jinwoo Shin SIAM Journal on Scientific Computing (SISC) 2017 Large-scale Log-determinant Computation through Stochastic Chebyshev Expansions [paper][code][video] Insu Han, Dmitry Malioutov, and Jinwoo Shin International Conference on Machine Learning (ICML) 2015","author":{"@type":"Person","name":"Insu Han"},"@type":"BlogPosting","url":"http://143.248.53.212:4000/intro/2021/02/26/about-me.html","headline":"About Me","dateModified":"2021-02-26T23:23:36+09:00","datePublished":"2021-02-26T23:23:36+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://143.248.53.212:4000/intro/2021/02/26/about-me.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->
</head>
<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
<link rel="stylesheet" href="/assets/font-awesome/css/font-awesome.min.css">
<body>
	<main class="container">
		<section class="about">
			<a href="https://insuhan.github.io">
			<img src="/assets/InsuHan.jpg" alt="Insu Han">
			</a>
			<h2>Insu Han</h2>
			<p class="tagline">Yale University</p>
			<ul class="social"><a href="https://github.com/insuhan"><li><i class="icon-github-circled"></i></li></a><a href="https://www.linkedin.com/in/insu-han-9b9676143/"><li><i class="icon-linkedin-squared"></i></li></a><a href="https://scholar.google.com/citations?hl=en&user=0w39xsoAAAAJ"><li><i class="ai ai-google-scholar-square ai-1x"></i></a>
			</ul>
			<p>&copy; 2022</p>
		</section>
		<section class="content">
			<div class="post-container">
  <a class="post-link" href="/intro/2021/02/26/about-me.html">
    <h2 class="post-title">About Me</h2>
  </a>
<!--   <div class="post-meta"> -->
<!--     <ul class="post-categories"> -->
<!---->
<!--       <li>intro</li> -->
<!---->
<!--     </ul> -->
<!--     <div class="post-date"><i class="icon-calendar"></i>Feb 26, 2021</div> -->
<!--   </div> -->
  <div class="post">
    <p>I am a postdoc in the Department of Electrical Engineering at Yale University, working with Prof. <a href="http://iid.yale.edu/">Amin Karbasi</a>. Previously, I obtained my Ph.D. degree in the School of Electrical Engineering at Korea Advanced Institute of Science and Technology (KAIST), where I am advised by <a href="http://alinlab.kaist.ac.kr/shin.html">Jinwoo Shin</a>. I recieved an M.S. in Electrical engineering and a B.S. in Electrical Engineering and Mathematics (minored) from KAIST.  My research interests focus on approximate algorithm design and analysis for large-scale machine learning and its applications. Here is my <a href="https://www.dropbox.com/s/xgxu17r4ic0w089/cv.pdf?dl=0">CV</a>.</p>

<h2 id="contact">Contact</h2>
<p>Email : insu.han at yale.edu <br /></p>

<p><br /></p>
<h2 id="research-experiences">Research experiences</h2>
<hr />

<p>[Summer 2019] Research intern at Google New York City with <a href="http://jgillenw.com/">Jennifer Gillenwater</a> <br />
[Spring 2018] Visting student at Tel Aviv University with <a href="http://www.math.tau.ac.il/~haimav/">Haim Avron</a></p>

<p><br /></p>
<h2 id="awards">Awards</h2>
<hr />
<p>I am a recipient of <a href="https://www.microsoft.com/en-us/research/academic-program/fellowships-microsoft-research-asia/">Microsoft Research Asia Fellowship 2019</a>. <br /></p>

<p><br /></p>
<h2 id="publications">Publications</h2>
<hr />

<p><strong>Fast Neural Kernel Embeddings for General Activations</strong> <br />
[<a href="https://arxiv.org/pdf/2209.04121.pdf">paper</a>][<a href="https://github.com/insuhan/ntk_activations">code</a>]<br />
<u>Insu Han</u>, Amin Zandieh, Jaehoon Lee, Roman Novak, Lechao Xiao, Amin Karbasi<br />
To be appeared in Advances in Neural Information Processing Systems (NeurIPS) 2022
<br /></p>

<p><strong>Near Optimal Reconstruction of Spherical Harmonic Expansions</strong> <br />
[<a href="https://arxiv.org/pdf/2202.12995.pdf">paper</a>]<br />
Amir Zandieh, <u>Insu Han</u>, Haim Avron<br />
Under review
<br /></p>

<p><strong>Scalable MCMC Sampling for Nonsymmetric Determinantal Point Processes</strong> <br />
[<a href="https://arxiv.org/pdf/2207.00486.pdf">paper</a>][<a href="https://github.com/insuhan/ndpp-mcmc-sampling">code</a>]
<u>Insu Han</u>, Mike Gartrell, Elvis Dohmatob, Amin Karbasi<br />
International Conference on Machine Learning (ICML) 2022, Long Presentation (118/5630=2%)
<br /></p>

<p><strong>Random Gegenbauer Features for Scalable Kernel Methods</strong> <br />
[<a href="https://arxiv.org/pdf/2202.03474.pdf">paper</a>]<br />
<u>Insu Han</u>, Amir Zandieh, Haim Avron<br />
International Conference on Machine Learning (ICML) 2022, Long Presentation (118/5630=2%)
<br /></p>

<p><strong>Scalable Sampling for Nonsymmetric Determinantal Point Processes</strong> <br />
[<a href="https://openreview.net/forum?id=BB4e8Atc1eR">paper</a>][<a href="https://github.com/insuhan/nonsymmetric-dpp-sampling">code</a>]<br />
<u>Insu Han</u>, Mike Gartrell, Jennifer Gillenwater, Elvis Dohmatob, Amin Karbasi<br />
International Conference on Learning Representations (ICLR) 2022, Spotlight Presentation
<br /></p>

<p><strong>Scaling Neural Tangent Kernels via Sketching and Random Features</strong> <br />
[<a href="https://arxiv.org/pdf/2106.07880.pdf">paper</a>][<a href="https://github.com/insuhan/ntk-sketch-rf">code</a>]<br />
<u>Insu Han</u>, Amir Zandieh, Haim Avron, Neta Shoham, Chaewon Kim, Jinwoo Shin<br />
Advances in Neural Information Processing Systems (NeurIPS) 2021
<br /></p>

<p><strong>Scalable Learning and MAP Inference for Nonsymmetric Determinantal Point Processes</strong> <br />
[<a href="https://openreview.net/forum?id=HajQFbx_yB">paper</a>][<a href="https://github.com/cgartrel/nonsymmetric-DPP-learning/tree/scalable">code</a>]<br />
Mike Gartrell, <u>Insu Han</u>, Elvis Dohmatob, Jennifer Gillenwater and Victor-Emmanuel Brunel <br />
International Conference on Learning Representations (ICLR) 2021, Oral Presentation (58/2997=1.8%)
<br /></p>

<p><strong>Polynomial Tensor Sketch for Element-wise Function of Low-Rank Matrix</strong> <br />
[<a href="http://proceedings.mlr.press/v119/han20a/han20a.pdf">paper</a>][<a href="https://github.com/insuhan/polytensorsketch">code</a>]<br />
<u>Insu Han</u>, Haim Avron and Jinwoo Shin <br />
International Conference on Machine Learning (ICML) 2020
<br /></p>

<p><strong>MAP Inference for Customized Determinantal Point Processes via Maximum Inner Product Search</strong> <br />
[<a href="http://alinlab.kaist.ac.kr/resource/fastdppmap_aistats2020.pdf">paper</a>][<a href="https://github.com/insuhan/dppmapmips">code</a>]<br />
<u>Insu Han</u> and Jennifer Gillenwater <br />
International Conference on Artificial Intelligence and Statistics (AISTATS) 2020
<br /></p>

<p><strong>Stochastic Chebyshev Gradient Descent for Spectral Optimization</strong> <br />
[<a href="https://papers.nips.cc/paper/7968-stochastic-chebyshev-gradient-descent-for-spectral-optimization.pdf">paper</a>][<a href="http://alinlab.kaist.ac.kr/resource/poster_nips18_specopt.pdf">poster</a>][<a href="https://www.youtube.com/watch?v=0Sx9G3-fOwU&amp;feature=youtu.be">video</a>]<br />
<u>Insu Han</u>, Haim Avron and Jinwoo Shin <br />
Neural Information Processing Systems (NeurIPS) 2018, Spotlight Presentation (168/4856=3.5%)</p>

<p><strong>Faster Greedy MAP Inference for Determinantal Point Processes</strong> <br />
[<a href="http://proceedings.mlr.press/v70/han17a/han17a.pdf">paper</a>][<a href="https://github.com/insuhan/fastdppmap">code</a>][<a href="https://vimeo.com/240776466">video</a>]<br />
<u>Insu Han</u>, Prabhanjan Kambadur, Kyoungsoo Park and Jinwoo Shin <br />
International Conference on Machine Learning (ICML) 2017</p>

<p><strong>Approximating Spectral Sums of Large-scale Matrices using Stochastic Chebyshev Approximations</strong> <br />
[<a href="https://epubs.siam.org/doi/pdf/10.1137/16M1078148">paper</a>]<br />
<u>Insu Han</u>, Dmitry Malioutov, Haim Avron and Jinwoo Shin <br />
SIAM Journal on Scientific Computing (SISC) 2017</p>

<p><strong>Large-scale Log-determinant Computation through Stochastic Chebyshev Expansions</strong> <br />
[<a href="http://proceedings.mlr.press/v37/hana15.pdf">paper</a>][<a href="http://alinlab.kaist.ac.kr/resource/logdet_code.zip">code</a>][<a href="http://videolectures.net/icml2015_han_log_determinant_computation/">video</a>]<br />
<u>Insu Han</u>, Dmitry Malioutov, and Jinwoo Shin <br />
International Conference on Machine Learning (ICML) 2015</p>


  </div>
		</section>
	</main></body>
</html>
